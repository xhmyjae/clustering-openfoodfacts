{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering on Open Food Facts dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports libraries\n",
    "from scripts import analyse_columns, clean\n",
    "from scripts.kmeans import kmeans_clustering, plot_elbow_method\n",
    "from scripts.plots import plot_clusters_2d, plot_cluster_sizes, plot_feature_relationships\n",
    "from scripts.model_utils import load_model\n",
    "from scripts.dimension_reduction import reduce_dimensions\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import mlflow\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# mlflow.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Open Food Facts dataset csv\n",
    "path = \"data/en.openfoodfacts.org.products.csv\"\n",
    "\n",
    "df = pd.read_csv(path, \n",
    "                 sep='\\\\t', \n",
    "                 encoding=\"utf-8\",\n",
    "                 on_bad_lines='skip',\n",
    "                 nrows=300000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information about the dataset\n",
    "print(\"\\nFirst few rows:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display number of rows and columns\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show summary statistics of numeric columns\n",
    "# Display detailed summary statistics of numeric columns\n",
    "print(\"\\nSummary statistics of numeric columns:\")\n",
    "print(df.describe(include=[np.number], percentiles=[.05, .25, .5, .75, .95]))\n",
    "\n",
    "# Show additional statistics\n",
    "print(\"\\nSkewness of numeric columns:\")\n",
    "print(df.select_dtypes(include=[np.number]).skew())\n",
    "\n",
    "print(\"\\nKurtosis of numeric columns:\")\n",
    "print(df.select_dtypes(include=[np.number]).kurtosis())\n",
    "\n",
    "# Count number of non-null values for each numeric column\n",
    "print(\"\\nNumber of non-null values in numeric columns:\")\n",
    "print(df.select_dtypes(include=[np.number]).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only relevant columns (nutritional columns)\n",
    "\n",
    "# All other columns are irrelevant\n",
    "irrelevant_columns = [col for col in df.columns if not col.endswith('_100g')]\n",
    "\n",
    "# Manually remove energy-kcal_100g and fat_100g from irrelevant_columns\n",
    "irrelevant_columns.extend(['energy-kcal_100g', 'fat_100g'])\n",
    "\n",
    "\n",
    "# Clean dataset using the clean() function\n",
    "df_cleaned = clean.clean(df, irrelevant_columns=irrelevant_columns, missing_threshold=0.5)\n",
    "\n",
    "# Display cleaned dataset info\n",
    "print(\"\\nCleaned dataset shape:\", df.shape)\n",
    "print(\"\\nRemaining columns:\")\n",
    "print(df_cleaned.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values by filling with median for numeric columns\n",
    "# Using median instead of mean to be more robust to outliers\n",
    "df_cleaned = df_cleaned.fillna(df_cleaned.median())\n",
    "\n",
    "# Verify no more NaN values exist\n",
    "print(\"\\nNumber of NaN values remaining:\")\n",
    "print(df_cleaned.isna().sum().sum())\n",
    "\n",
    "# Display first few rows to verify changes\n",
    "print(\"\\nFirst few rows after handling missing values:\")\n",
    "display(df_cleaned.head())\n",
    "\n",
    "print(\"\\nShape\")\n",
    "print(df_cleaned.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(df_cleaned),\n",
    "    columns=df_cleaned.columns\n",
    ")\n",
    "\n",
    "# Display first few rows of scaled data\n",
    "print(\"First few rows of scaled data:\")\n",
    "display(df_scaled.head())\n",
    "\n",
    "# Verify scaling - mean should be ~0 and std should be ~1\n",
    "print(\"\\nMean of scaled features:\")\n",
    "print(df_scaled.mean().round(2))\n",
    "print(\"\\nStandard deviation of scaled features:\")\n",
    "print(df_scaled.std().round(2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers using IQR method\n",
    "def remove_outliers(df):\n",
    "    Q1 = df.quantile(0.25)\n",
    "    Q3 = df.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    # Define bounds\n",
    "    lower_bound = Q1 - 1.5 * IQR \n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Create mask for values within bounds\n",
    "    mask = ~((df < lower_bound) | (df > upper_bound)).any(axis=1)\n",
    "    \n",
    "    return df[mask]\n",
    "\n",
    "# Remove outliers and store in new DataFrame\n",
    "print(\"Shape before removing outliers:\", df_scaled.shape)\n",
    "df_scaled_no_outliers = remove_outliers(df_scaled)\n",
    "print(\"Shape after removing outliers:\", df_scaled_no_outliers.shape)\n",
    "print(f\"Removed {df_scaled.shape[0] - df_scaled_no_outliers.shape[0]} outliers\")\n",
    "\n",
    "# Update original data without outliers for consistency\n",
    "df_cleaned = df_cleaned.loc[df_scaled_no_outliers.index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cleaned dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do PCA to visualize high-dimensional data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature importance and correlations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dimensionality Reduction\n",
    "print(\"Original data shape:\", df_cleaned.shape)\n",
    "\n",
    "# Apply UMAP reduction\n",
    "reduced_data = reduce_dimensions(df_cleaned.values)\n",
    "print(\"Reduced data shape:\", reduced_data.shape)\n",
    "\n",
    "# Visualize the reduced data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(reduced_data[:, 0], reduced_data[:, 1], alpha=0.5)\n",
    "plt.title('UMAP Projection of the Data')\n",
    "plt.xlabel('UMAP 1')\n",
    "plt.ylabel('UMAP 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine optimal number of clusters\n",
    "plot_elbow_method(reduced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform clustering\n",
    "kmeans, labels, metrics = kmeans_clustering(reduced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot clusters in the reduced space\n",
    "plot_clusters_2d(reduced_data, labels, \n",
    "                title=\"K-means Clustering Results on UMAP Reduced Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show cluster sizes\n",
    "plot_cluster_sizes(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Feature Analysis\n",
    "# Create feature relationship plots using original data\n",
    "feature_names = df_cleaned.columns.tolist()\n",
    "plot_feature_relationships(\n",
    "    data=df_cleaned.values,  # Using original data, not reduced_data\n",
    "    labels=labels,\n",
    "    feature_names=feature_names,\n",
    "    n_features=5  # Adjust based on how many features you want to compare\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Mixture Model (GMM) clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierarchical clustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster evaluation and comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare clustering results using metrics (Silhouette score, Calinski-Harabasz index, Davies-Bouldin index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize cluster comparisons (word clouds, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse cluster characteristics and interpret results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Various visualizations (cluster distribution plots, feature importance within clusters, pairplots with key features, heatmaps of cluster characteristics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate insights about food product groupings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indentify patterns and trends in the clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions and recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize findings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare strengths and weaknesses of different clustering methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide recommendations for practical applications\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suggest potential areas for futher analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clustering-openfoodfacts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
